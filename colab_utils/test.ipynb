{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initialize network with normal\n",
      "model [Pix2PixModel] was created\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from models import create_model\n",
    "\n",
    "\n",
    "class Options:\n",
    "    def __init__(self):\n",
    "        self.model = 'pix2pix'\n",
    "        self.gpu_ids = []\n",
    "        self.isTrain = False\n",
    "        self.checkpoints_dir = './checkpoints/floorplan_model'\n",
    "        self.name = 'floorplan'\n",
    "        self.preprocess = None\n",
    "        self.input_nc = 3\n",
    "        self.output_nc = 3\n",
    "        self.ngf = 64\n",
    "        self.netG = 'unet_256'\n",
    "        self.netD = 'basic'\n",
    "        self.norm = 'batch'\n",
    "        self.no_dropout = True\n",
    "        self.init_type = 'normal'\n",
    "        self.init_gain = 0.02\n",
    "\n",
    "opt = Options()\n",
    "model = create_model(opt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "model.netG.load_state_dict(torch.load('checkpoints/floorplan_model/130_net_G.pth'))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import torchvision.transforms as transforms\n",
    "import torch\n",
    "\n",
    "def gen_image(input_image):\n",
    "    # Define the transformations\n",
    "    transform = transforms.Compose([\n",
    "        transforms.Resize((256, 256)),  # Resize to the size that your model expects\n",
    "        transforms.ToTensor(),  # Convert the PIL Image to a tensor\n",
    "        transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))  # Normalize the tensor\n",
    "    ])\n",
    "\n",
    "    # Apply the transformations\n",
    "    input_tensor = transform(input_image)\n",
    "\n",
    "    # Add an extra batch dimension since pytorch treats all images as batches\n",
    "    input_tensor = input_tensor.unsqueeze(0)\n",
    "\n",
    "    # Ensure the tensor is on the same device as the model\n",
    "    input_tensor = input_tensor.to(next(model.netG.parameters()).device)\n",
    "\n",
    "    # Pass the tensor through the model\n",
    "    with torch.no_grad():\n",
    "        output_tensor = model.netG(input_tensor)\n",
    "\n",
    "    # Remove the batch dimension\n",
    "    output_tensor = output_tensor.squeeze(0)\n",
    "\n",
    "    # Convert the tensor to an image\n",
    "    output_image = transforms.ToPILImage()(output_tensor)\n",
    "\n",
    "    return output_image"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load the input image\n",
    "list_images = os.listdir('predicted_wob_imgs')\n",
    "input_image = Image.open('predicted_wob_imgs/' + random.choice(list_images))\n",
    "\n",
    "# Display the images\n",
    "fig, ax = plt.subplots(1, 2, figsize=(10, 5))\n",
    "ax[0].imshow(input_image)\n",
    "ax[0].set_title('Input Image')\n",
    "ax[0].axis('off')\n",
    "\n",
    "output_image = gen_image(input_image)\n",
    "ax[1].imshow(output_image)\n",
    "ax[1].set_title('Output Image')\n",
    "ax[1].axis('off')\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
